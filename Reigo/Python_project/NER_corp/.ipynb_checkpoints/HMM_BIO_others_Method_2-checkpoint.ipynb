{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2882b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "class HmmModel:\n",
    "\n",
    "    def __init__(self):\n",
    "        # 分词状态\n",
    "        self.STATE = {'B', 'M', 'E', 'S'}\n",
    "        # 状态转移矩阵\n",
    "        self.A_dict = {}\n",
    "        # 发射矩阵\n",
    "        self.B_dict = {}\n",
    "        # 初始矩阵\n",
    "        self.Pi_dict = {}\n",
    "\n",
    "    # 加载数据 先加载模型数据，没有就读取语料库重新训练\n",
    "    def load(self, model_file='../dataset/hmm/model.pkl', train_file='../dataset/hmm/train.txt'):\n",
    "\n",
    "        # 加载模型数据\n",
    "        try:\n",
    "            with open(model_file, 'rb') as f:\n",
    "                self.A_dict = pickle.load(f)\n",
    "                self.B_dict = pickle.load(f)\n",
    "                self.Pi_dict = pickle.load(f)\n",
    "                return\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "        # 统计状态出现次数 方便求发射矩阵\n",
    "        Count_dict = {}\n",
    "        # 存放初始语料所有数据\n",
    "        data = []\n",
    "        # 存放初始语料中的一个句子\n",
    "        sentence = []\n",
    "\n",
    "        # 初始化模型参数\n",
    "        def init_params():\n",
    "            for state in self.STATE:\n",
    "                self.A_dict[state] = {s: 0.0 for s in self.STATE}\n",
    "                self.Pi_dict[state] = 0.0\n",
    "                self.B_dict[state] = {}\n",
    "                Count_dict[state] = 0\n",
    "\n",
    "        init_params()\n",
    "\n",
    "        # 读取语料库\n",
    "        with open(train_file, encoding='utf8') as f:\n",
    "            # 每句按元组存在data中\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                word_list = [i for i in line if i != '\\t']\n",
    "                if not line:\n",
    "                    data.append(sentence)\n",
    "                    sentence = []\n",
    "                else:\n",
    "                    sentence.append((word_list[0], word_list[1]))\n",
    "\n",
    "            # 统计次数\n",
    "            for s in data:\n",
    "                for k, v in enumerate(s):\n",
    "                    Count_dict[v[1]] += 1\n",
    "                    if k == 0:\n",
    "                        self.Pi_dict[v[1]] += 1  # 每个句子的第一个字的状态，用于计算初始状态概率\n",
    "                    else:\n",
    "                        self.A_dict[s[k - 1][1]][v[1]] += 1  # 计算转移概率\n",
    "                        self.B_dict[s[k][1]][v[0]] = self.B_dict[s[k][1]].get(v[0], 0) + 1.0  # 计算发射概率\n",
    "\n",
    "            # 计算频率\n",
    "            self.Pi_dict = {k: v * 1.0 / len(data) for k, v in self.Pi_dict.items()}\n",
    "            self.A_dict = {k: {k1: v1 / Count_dict[k] for k1, v1 in v.items()} for k, v in self.A_dict.items()}\n",
    "            # 加1平滑\n",
    "            self.B_dict = {k: {k1: (v1 + 1) / Count_dict[k] for k1, v1 in v.items()} for k, v in self.B_dict.items()}\n",
    "\n",
    "            # 把中间模型数据保存下来\n",
    "            self.save()\n",
    "\n",
    "    # 保存中间模型数据\n",
    "    def save(self, model_file='../dataset/hmm/model.pkl'):\n",
    "        # 序列化\n",
    "        import pickle\n",
    "        with open(model_file, 'wb') as f:\n",
    "            pickle.dump(self.A_dict, f)\n",
    "            pickle.dump(self.B_dict, f)\n",
    "            pickle.dump(self.Pi_dict, f)\n",
    "\n",
    "    # 维特比算法\n",
    "    def viterbi(self, text):\n",
    "        # 加载数据\n",
    "        self.load()\n",
    "        # 赋别名\n",
    "        states, start_p, trans_p, emit_p = self.STATE, self.Pi_dict, self.A_dict, self.B_dict\n",
    "        # 初始化顶点集、路径集\n",
    "        V = [{}]\n",
    "        path = {}\n",
    "        # 初始化第一个状态\n",
    "        for y in states:\n",
    "            V[0][y] = start_p[y] * emit_p[y].get(text[0], 0)\n",
    "            path[y] = [y]\n",
    "\n",
    "        # 遍历剩下的状态\n",
    "        for t in range(1, len(text)):\n",
    "            V.append({})\n",
    "            newpath = {}\n",
    "\n",
    "            # 检验训练的发射概率矩阵中是否有该字\n",
    "            neverSeen = text[t] not in emit_p['S'].keys() and \\\n",
    "                        text[t] not in emit_p['M'].keys() and \\\n",
    "                        text[t] not in emit_p['E'].keys() and \\\n",
    "                        text[t] not in emit_p['B'].keys()\n",
    "\n",
    "            for y in states:\n",
    "                # 生词值为1，发射矩阵一行内词找不到为0(发射矩阵有4行)\n",
    "                emitP = emit_p[y].get(text[t], 0) if not neverSeen else 1.0  # 设置未知字单独成词\n",
    "\n",
    "                # 在当前状态为y下，计算前一个时刻的四种状态的代价乘积，取max\n",
    "                (prob, state) = max(\n",
    "                    [(V[t - 1][y0] * trans_p[y0].get(y, 0) *\n",
    "                      emitP, y0)\n",
    "                     for y0 in states if V[t - 1][y0] > 0])\n",
    "\n",
    "                V[t][y] = prob\n",
    "\n",
    "                newpath[y] = path[state] + [y]\n",
    "            path = newpath\n",
    "\n",
    "        if emit_p['M'].get(text[-1], 0) > emit_p['S'].get(text[-1], 0):\n",
    "            (prob, state) = max([(V[len(text) - 1][y], y) for y in ('E', 'M')])\n",
    "        else:\n",
    "            (prob, state) = max([(V[len(text) - 1][y], y) for y in states])\n",
    "\n",
    "        return (prob, path[state])\n",
    "\n",
    "    def cut(self, text):\n",
    "        prob, pos_list = self.viterbi(text)\n",
    "        begin, next = 0, 0\n",
    "        for i, char in enumerate(text):\n",
    "            pos = pos_list[i]\n",
    "            if pos == 'B':\n",
    "                begin = i\n",
    "            elif pos == 'E':\n",
    "                yield text[begin: i + 1]\n",
    "                next = i + 1\n",
    "            elif pos == 'S':\n",
    "                yield char\n",
    "                next = i + 1\n",
    "        if next < len(text):\n",
    "            yield text[next:]\n",
    "\n",
    "\n",
    "\n",
    "hmm = HmmModel()\n",
    "text = '人类社会前进的航船就要驶入21世纪的新航程。'\n",
    "res = hmm.cut(text)\n",
    "print(str(list(res)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b271ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建一个HMM模型\n",
    "model = HMM_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f9c9bdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练数据：\n",
      "0 1 : 一 2\n",
      "1 28 : 二 2\n",
      "2 51 : 三 2\n",
      "3 76 : 四 2\n",
      "4 83 : 合 2\n",
      "5 108 : 供 2\n",
      "6 114 : 供 2\n",
      "7 120 : 中 2\n",
      "8 129 : 深 0\n",
      "9 143 : 深 2\n",
      "10 173 : 1 2\n",
      "11 187 : 五 2\n",
      "12 196 : 合 2\n",
      "13 221 : 货 2\n",
      "14 240 : 品 2\n",
      "15 244 : 品 2\n",
      "16 249 : 采 2\n",
      "17 254 : 品 2\n",
      "18 257 : 规 2\n",
      "19 262 : 数 2\n",
      "20 269 : 单 2\n",
      "21 275 : 总 2\n",
      "22 281 : 1 2\n",
      "23 285 : 其 2\n",
      "24 291 : 龙 0\n",
      "25 308 : 详 2\n",
      "26 313 : 详 2\n",
      "27 318 : 1 2\n",
      "28 323 : 1 2\n",
      "29 336 : 1 2\n",
      "30 349 : 六 2\n",
      "31 369 : 评 0\n",
      "32 380 : 随 2\n",
      "33 397 : 采 2\n",
      "34 409 : 自 2\n",
      "35 420 : 七 2\n",
      "36 435 : 代 2\n",
      "37 446 : 按 2\n",
      "38 477 : 代 2\n",
      "39 486 : 合 2\n",
      "40 520 : 收 2\n",
      "41 536 : 八 2\n",
      "42 543 : 自 2\n",
      "43 559 : 九 2\n",
      "44 568 : 合 2\n",
      "45 593 : 供 2\n",
      "46 597 : 资 2\n",
      "47 603 : 符 2\n",
      "48 609 : 技 2\n",
      "49 614 : 商 2\n",
      "50 619 : 价 2\n",
      "51 624 : 综 2\n",
      "52 629 : 得 2\n",
      "53 634 : 推 2\n",
      "54 639 : 深 0\n",
      "55 653 : 通 2\n",
      "56 656 : 通 2\n",
      "57 659 : 4 2\n",
      "58 665 : 1 2\n",
      "59 671 : 2 2\n",
      "60 677 : 9 2\n",
      "61 683 : 1 2\n",
      "62 685 : 1 2\n",
      "63 687 : 安 0\n",
      "64 704 : 通 2\n",
      "65 707 : 通 2\n",
      "66 710 : 3 2\n",
      "67 716 : 7 2\n",
      "68 721 : 2 2\n",
      "69 727 : 6 2\n",
      "70 733 : 2 2\n",
      "71 735 : 2 2\n",
      "72 737 : 深 0\n",
      "73 750 : 通 2\n",
      "74 753 : 通 2\n",
      "75 756 : 2 2\n",
      "76 762 : 3 2\n",
      "77 767 : 3 2\n",
      "78 773 : 6 2\n",
      "79 779 : 3 2\n",
      "80 781 : 3 2\n",
      "81 783 : 十 2\n",
      "82 808 : 1 2\n",
      "83 816 : 名 2\n",
      "84 827 : 地 2\n",
      "85 844 : 联 2\n",
      "86 862 : 2 2\n",
      "87 873 : 名 2\n",
      "88 890 : 地 2\n",
      "89 935 : 联 2\n",
      "90 953 : 3 2\n",
      "91 962 : 项 2\n",
      "92 972 : 电 2\n",
      "93 989 : 广 0\n",
      "94 1002 : 2 2\n",
      "[ 7.  0. 88.]\n",
      "[[  0.  17.   0.]\n",
      " [  0. 122.  10.]\n",
      " [ 10.   0. 664.]]\n",
      "训练参数已保存在 param/short1/A.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "# model.train('corpus/corpus_part0.txt')\n",
    "model.train('corpus/corpus_1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4458170f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练参数(A,B,PI)已从 param/short1/A.csv 中读取成功\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#从训练好的模型加载参数\n",
    "model.load_Param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "866a1db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "家O_|乐B-ORG_|福B-ORG_|\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "s='家乐福'\n",
    "print(model.predict(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "37f404a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "林B-ORG_|徽I-ORG_|因I-ORG_|什I-ORG_|么I-ORG_|理I-ORG_|由I-ORG_|拒I-ORG_|绝I-ORG_|了I-ORG_|徐I-ORG_|志O_|摩O_|而O_|选O_|择B-ORG_|梁I-ORG_|思I-ORG_|成O_|变B-ORG_|为I-ORG_|终I-ORG_|身I-ORG_|伴I-ORG_|侣I-ORG_|?I-ORG_|谢I-ORG_|娜I-ORG_|为I-ORG_|李I-ORG_|浩I-ORG_|菲I-ORG_|澄I-ORG_|清I-ORG_|网I-ORG_|络I-ORG_|谣I-ORG_|言I-ORG_|，I-ORG_|之O_|后O_|她O_|的O_|两O_|个O_|行O_|为O_|给O_|自O_|己O_|加O_|分O_|\n",
      "\n",
      "王B-ORG_|心I-ORG_|雷I-ORG_|编O_|写O_|了O_|一O_|个O_|代O_|码O_|\n",
      "\n",
      "王O_|康B-ORG_|在I-ORG_|哈I-ORG_|尔I-ORG_|滨I-ORG_|出O_|门B-ORG_|打I-ORG_|电I-ORG_|动I-ORG_|被I-ORG_|张I-ORG_|舒I-ORG_|帆I-ORG_|当I-ORG_|场I-ORG_|逮I-ORG_|捕I-ORG_|\n",
      "\n",
      "北B-ORG_|京I-ORG_|抖I-ORG_|音I-ORG_|信O_|息O_|服O_|务B-ORG_|有I-ORG_|限I-ORG_|公I-ORG_|司I-ORG_|今I-ORG_|天I-ORG_|出O_|台O_|了O_|一O_|个O_|新O_|的O_|政B-ORG_|策I-ORG_|\n",
      "\n",
      "中O_|国B-ORG_|招I-ORG_|标I-ORG_|网I-ORG_|发I-ORG_|布O_|了O_|一O_|个O_|新B-ORG_|的I-ORG_|招I-ORG_|标I-ORG_|\n",
      "\n",
      "我B-ORG_|真I-ORG_|的O_|好B-ORG_|饿I-ORG_|\n",
      "\n",
      "中O_|标O_|人O_|:O_|遂B-ORG_|宁I-ORG_|高I-ORG_|新I-ORG_|区O_|蜜O_|感O_|内O_|衣B-ORG_|店I-ORG_|\n",
      "\n",
      "中O_|国B-ORG_|是I-ORG_|个O_|好O_|地O_|方O_|\n",
      "\n",
      "宁B-ORG_|夏I-ORG_|最I-ORG_|高I-ORG_|气I-ORG_|温I-ORG_|2O_|0O_|度O_|\n",
      "\n",
      "恭B-ORG_|喜I-ORG_|安O_|居O_|区O_|安B-ORG_|居I-ORG_|镇I-ORG_|有I-ORG_|家I-ORG_|超I-ORG_|市I-ORG_|昨I-ORG_|天I-ORG_|开I-ORG_|业I-ORG_|了I-ORG_|\n",
      "\n",
      "家O_|乐B-ORG_|福I-ORG_|是I-ORG_|个O_|好O_|地O_|方O_|\n",
      "\n",
      "家O_|乐B-ORG_|福I-ORG_|\n",
      "\n",
      "家O_|乐B-ORG_|福I-ORG_|超I-ORG_|市I-ORG_|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#进行预测(copus_part0_others_method1)\n",
    "sentences=['林徽因什么理由拒绝了徐志摩而选择梁思成变为终身伴侣?谢娜为李浩菲澄清网络谣言，之后她的两个行为给自己加分','王心雷编写了一个代码',\n",
    "      '王康在哈尔滨出门打电动被张舒帆当场逮捕','北京抖音信息服务有限公司今天出台了一个新的政策','中国招标网发布了一个新的招标',\n",
    "       '我真的好饿','中标人:遂宁高新区蜜感内衣店','中国是个好地方','宁夏最高气温20度','恭喜安居区安居镇有家超市昨天开业了',\n",
    "           '家乐福是个好地方','家乐福','家乐福超市']\n",
    "for sentence in sentences:\n",
    "    model.predict(sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3c2e1ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12289\n",
      "一\n"
     ]
    }
   ],
   "source": [
    "print(ord('、'))\n",
    "print(chr(19968))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
